{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4r9kOd7e-FiR"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyCTPM1Ywg/DHbh4elBnZF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hallpaz/udl/blob/main/code/mr-imaging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Deep Learning 2024\n",
        "# Multiresolution Representation of Images\n",
        "\n",
        "#### by Hallison Paz\n",
        "#### October 15th, 2024"
      ],
      "metadata": {
        "id": "4r9kOd7e-FiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "HTML('''<iframe width=\"560\" height=\"315\"\n",
        "        src=\"https://www.youtube.com/embed/WmaWecH0ThU?si=IlFcrojnGMReHle5\"\n",
        "        frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media;\n",
        "        gyroscope; picture-in-picture\" allowfullscreen></iframe>''')"
      ],
      "metadata": {
        "id": "-Yki6Mde-Krk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eczHIRmpNyG_"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/visgraf/mrnet.git@dev\n",
        "!pip install wandb\n",
        "!pip install trimesh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "from mrnet.training.trainer import MRTrainer\n",
        "from mrnet.datasets.signals import ImageSignal\n",
        "from mrnet.networks.mrnet import MRFactory\n",
        "from mrnet.datasets.pyramids import create_MR_structure\n",
        "from mrnet.training.listener import TrainingListener\n",
        "\n",
        "from mrnet.training.utils import load_hyperparameters, get_optim_handler"
      ],
      "metadata": {
        "id": "sEPon5oBOHRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p configs/\n",
        "!mkdir -p data/\n",
        "!wget -P configs https://raw.githubusercontent.com/hallpaz/udl/refs/heads/main/code/image.yml\n",
        "!wget -P data https://raw.githubusercontent.com/hallpaz/udl/refs/heads/main/data/masp.jpg"
      ],
      "metadata": {
        "id": "zEhvnl8jOTiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a MR-Net Model"
      ],
      "metadata": {
        "id": "wm1Zxu6S8fKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_PATH = 'configs'"
      ],
      "metadata": {
        "id": "DITCUtWcOOn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(777)\n",
        "#-- hyperparameters in configs --#\n",
        "hyper = load_hyperparameters(os.path.join(CONFIG_PATH, 'image.yml'))\n",
        "project_name = hyper.get('project_name', 'framework-tests')"
      ],
      "metadata": {
        "id": "h1QSeQRVQ5qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_signal = ImageSignal.init_fromfile(\n",
        "                    hyper['data_path'],\n",
        "                    domain=hyper['domain'],\n",
        "                    channels=hyper['channels'],\n",
        "                    sampling_scheme=hyper['sampling_scheme'],\n",
        "                    width=hyper['width'], height=hyper['height'],\n",
        "                    batch_size=hyper['batch_size'],\n",
        "                    color_space=hyper['color_space'])\n",
        "\n",
        "train_dataset = create_MR_structure(base_signal,\n",
        "                                    hyper['max_stages'],\n",
        "                                    hyper['filter'],\n",
        "                                    hyper['decimation'],\n",
        "                                    hyper['pmode'])\n",
        "test_dataset = create_MR_structure(base_signal,\n",
        "                                    hyper['max_stages'],\n",
        "                                    hyper['filter'],\n",
        "                                    False,\n",
        "                                    hyper['pmode'])\n",
        "\n",
        "if hyper['width'] == 0:\n",
        "    hyper['width'] = base_signal.shape[-1]\n",
        "if hyper['height'] == 0:\n",
        "    hyper['height'] = base_signal.shape[-1]\n",
        "\n",
        "# you can substitute this line by your custom handler class\n",
        "optim_handler = get_optim_handler(hyper.get('optim_handler', 'regular'))\n",
        "\n",
        "mrmodel = MRFactory.from_dict(hyper)\n",
        "print(\"Model: \", type(mrmodel))\n",
        "name = os.path.basename(hyper['data_path'])\n",
        "logger = TrainingListener(project_name,\n",
        "                            f\"{hyper['model']}{hyper['filter'][0].upper()}{name[0:7]}{hyper['color_space'][0]}\",\n",
        "                            hyper,\n",
        "                            Path(hyper.get(\"log_path\", \"runs\")))\n",
        "mrtrainer = MRTrainer.init_from_dict(mrmodel,\n",
        "                                    train_dataset,\n",
        "                                    test_dataset,\n",
        "                                    logger,\n",
        "                                    hyper,\n",
        "                                    optim_handler=optim_handler)\n",
        "mrtrainer.train(hyper['device'])"
      ],
      "metadata": {
        "id": "s4n9_XKdN-F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the model scales"
      ],
      "metadata": {
        "id": "EWfehSFD8B8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from ipywidgets import interact, interactive, Box, interact_manual\n",
        "from mrnet.datasets.sampler import make_grid_coords"
      ],
      "metadata": {
        "id": "82KNdGxu8CSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelpath = input(\"Path to the saved model parameters file: \")\n",
        "mrmodel = MRFactory.load_state_dict(modelpath)\n",
        "print('modelpath:', modelpath)"
      ],
      "metadata": {
        "id": "-OnlQi_m8IKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = hyper['width']\n",
        "channels = hyper['channels']\n",
        "model = mrmodel\n",
        "\n",
        "level_slider = widgets.FloatSlider(\n",
        "        value=1.0,\n",
        "        min=0.0,\n",
        "        max=float(mrmodel.n_stages()),\n",
        "        step=0.05,\n",
        "        description=f'Multilevel',\n",
        "        disabled=False,\n",
        "        continuous_update=True,\n",
        "        readout=True,\n",
        "        orientation='horizontal',\n",
        "        readout_format='.2f',\n",
        "        layout=widgets.Layout(width='50%')\n",
        ")\n",
        "def plot_model(level):\n",
        "    grid = make_grid_coords(res, -1.0, 1.0, dim=2)\n",
        "    weights = []\n",
        "    for s in range(mrmodel.n_stages()):\n",
        "        if level >= s + 1:\n",
        "             weights.append(1.0)\n",
        "        else:\n",
        "             weights.append(max(level - s, 0.0))\n",
        "\n",
        "    output = model(grid, mrweights=torch.Tensor(weights))\n",
        "    model_out = torch.clamp(output['model_out'], 0.0, 1.0)\n",
        "\n",
        "    pixels = model_out.cpu().detach().view(res, res, channels).numpy()\n",
        "    pixels = (pixels * 255).astype(np.uint8)\n",
        "    if channels == 1:\n",
        "        pixels = np.repeat(pixels, 3, axis=-1)\n",
        "    return Image.fromarray(pixels)\n",
        "\n",
        "interact(plot_model, level=level_slider)"
      ],
      "metadata": {
        "id": "TgMyl73P8J8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}